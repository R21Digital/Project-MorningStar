#!/bin/bash

# =============================================================================
# Project MorningStar - Public Launch Go-Live Script
# Batch 200 - Public Launch Prep & Go-Live Script
# 
# This script handles the complete launch preparation and deployment process
# for bringing the MorningStar project (SWGDB + MS11) to public availability.
# =============================================================================

set -euo pipefail

# Script metadata
SCRIPT_VERSION="1.0.0"
SCRIPT_NAME="MorningStar Go-Live Script"
LAUNCH_DATE=$(date +"%Y-%m-%d %H:%M:%S")
LOG_DIR="logs/deployment"
LOG_FILE="$LOG_DIR/go_live_$(date +%Y%m%d_%H%M%S).log"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
WHITE='\033[1;37m'
NC='\033[0m' # No Color

# Configuration
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
CONFIG_DIR="$PROJECT_ROOT/config"
DEPLOY_CONFIG="$CONFIG_DIR/deploy/live.json"
BUILD_DIR="$PROJECT_ROOT/dist"
BACKUP_DIR="$PROJECT_ROOT/backups/pre_launch_$(date +%Y%m%d_%H%M%S)"

# Load deployment configuration
if [[ -f "$DEPLOY_CONFIG" ]]; then
    # Parse JSON config (requires jq)
    if command -v jq >/dev/null 2>&1; then
        DOMAIN=$(jq -r '.domain' "$DEPLOY_CONFIG" 2>/dev/null || echo "")
        CDN_ENABLED=$(jq -r '.cdn.enabled' "$DEPLOY_CONFIG" 2>/dev/null || echo "false")
        ANALYTICS_ENABLED=$(jq -r '.analytics.enabled' "$DEPLOY_CONFIG" 2>/dev/null || echo "true")
        DISCORD_WEBHOOK_URL=$(jq -r '.notifications.discord.webhook_url' "$DEPLOY_CONFIG" 2>/dev/null || echo "")
    fi
fi

# Default values if config not available
DOMAIN=${DOMAIN:-"morningstar.swg.ms11.com"}
CDN_ENABLED=${CDN_ENABLED:-"false"}
ANALYTICS_ENABLED=${ANALYTICS_ENABLED:-"true"}
DISCORD_WEBHOOK_URL=${DISCORD_WEBHOOK_URL:-""}

# Function definitions
log() {
    local level="$1"
    shift
    local message="$*"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    # Ensure log directory exists
    mkdir -p "$LOG_DIR"
    
    # Write to log file
    echo "[$timestamp] [$level] $message" >> "$LOG_FILE"
    
    # Also output to console with colors
    case "$level" in
        "INFO")  echo -e "${CYAN}â„¹ï¸  $message${NC}" ;;
        "WARN")  echo -e "${YELLOW}âš ï¸  $message${NC}" ;;
        "ERROR") echo -e "${RED}âŒ $message${NC}" ;;
        "SUCCESS") echo -e "${GREEN}âœ… $message${NC}" ;;
        "DEBUG") echo -e "${PURPLE}ðŸ” $message${NC}" ;;
        *) echo -e "${WHITE}$message${NC}" ;;
    esac
}

print_header() {
    echo -e "${BLUE}"
    echo "============================================================"
    echo "ðŸš€ $SCRIPT_NAME v$SCRIPT_VERSION"
    echo "============================================================"
    echo -e "${NC}"
    echo "Launch Date: $LAUNCH_DATE"
    echo "Project Root: $PROJECT_ROOT"
    echo "Domain: $DOMAIN"
    echo "CDN Enabled: $CDN_ENABLED"
    echo "Analytics Enabled: $ANALYTICS_ENABLED"
    echo ""
}

check_prerequisites() {
    log "INFO" "Checking prerequisites..."
    
    local missing_tools=()
    
    # Check required tools
    local required_tools=("node" "npm" "python3" "git")
    for tool in "${required_tools[@]}"; do
        if ! command -v "$tool" >/dev/null 2>&1; then
            missing_tools+=("$tool")
        fi
    done
    
    # Check optional tools
    if ! command -v "jq" >/dev/null 2>&1; then
        log "WARN" "jq not found - JSON parsing will be limited"
    fi
    
    if ! command -v "curl" >/dev/null 2>&1; then
        log "WARN" "curl not found - CDN purge and webhooks may not work"
    fi
    
    if [[ ${#missing_tools[@]} -ne 0 ]]; then
        log "ERROR" "Missing required tools: ${missing_tools[*]}"
        log "ERROR" "Please install missing tools and try again"
        exit 1
    fi
    
    log "SUCCESS" "All prerequisites met"
}

validate_project_structure() {
    log "INFO" "Validating project structure..."
    
    local required_dirs=(
        "src"
        "config"
        "data"
        "scripts"
        "api"
        "website"
        "swgdb_site"
    )
    
    local required_files=(
        "README.md"
        "package.json"
        "requirements.txt"
        "Makefile"
        ".github/workflows/tests.yml"
    )
    
    local missing_items=()
    
    # Check directories
    for dir in "${required_dirs[@]}"; do
        if [[ ! -d "$PROJECT_ROOT/$dir" ]]; then
            missing_items+=("Directory: $dir")
        fi
    done
    
    # Check files
    for file in "${required_files[@]}"; do
        if [[ ! -f "$PROJECT_ROOT/$file" ]]; then
            missing_items+=("File: $file")
        fi
    done
    
    # Check for critical config files
    local config_files=(
        "config/webhooks.json"
        "config/discord_config.json"
        "config/safety_defaults.json"
    )
    
    for config_file in "${config_files[@]}"; do
        if [[ ! -f "$PROJECT_ROOT/$config_file" ]]; then
            log "WARN" "Optional config file missing: $config_file"
        fi
    done
    
    if [[ ${#missing_items[@]} -ne 0 ]]; then
        log "ERROR" "Missing critical project structure:"
        for item in "${missing_items[@]}"; do
            log "ERROR" "  - $item"
        done
        exit 1
    fi
    
    log "SUCCESS" "Project structure validation passed"
}

create_required_directories() {
    log "INFO" "Creating required directories..."
    
    local directories=(
        "$BUILD_DIR"
        "$BACKUP_DIR"
        "$LOG_DIR"
        "$PROJECT_ROOT/uploads"
        "$PROJECT_ROOT/cache"
        "$PROJECT_ROOT/tmp"
        "$CONFIG_DIR/deploy"
        "$PROJECT_ROOT/public/assets"
    )
    
    for dir in "${directories[@]}"; do
        if [[ ! -d "$dir" ]]; then
            mkdir -p "$dir"
            log "INFO" "Created directory: $dir"
        fi
    done
    
    log "SUCCESS" "Required directories created"
}

backup_current_state() {
    log "INFO" "Creating pre-launch backup..."
    
    # Create backup directory
    mkdir -p "$BACKUP_DIR"
    
    # Backup critical files and directories
    local backup_items=(
        "config"
        "data"
        "src"
        "api"
        "README.md"
        "package.json"
        "requirements.txt"
    )
    
    for item in "${backup_items[@]}"; do
        if [[ -e "$PROJECT_ROOT/$item" ]]; then
            cp -r "$PROJECT_ROOT/$item" "$BACKUP_DIR/"
            log "INFO" "Backed up: $item"
        fi
    done
    
    # Create backup manifest
    cat > "$BACKUP_DIR/BACKUP_MANIFEST.txt" << EOF
MorningStar Pre-Launch Backup
Created: $LAUNCH_DATE
Script Version: $SCRIPT_VERSION
Domain: $DOMAIN

Backup Contents:
$(ls -la "$BACKUP_DIR")

Git Commit:
$(cd "$PROJECT_ROOT" && git rev-parse HEAD 2>/dev/null || echo "Not a git repository")

Git Status:
$(cd "$PROJECT_ROOT" && git status --porcelain 2>/dev/null || echo "Not a git repository")
EOF
    
    log "SUCCESS" "Backup created at: $BACKUP_DIR"
}

install_dependencies() {
    log "INFO" "Installing dependencies..."
    
    cd "$PROJECT_ROOT"
    
    # Install Python dependencies
    if [[ -f "requirements.txt" ]]; then
        log "INFO" "Installing Python dependencies..."
        python3 -m pip install --upgrade pip
        python3 -m pip install -r requirements.txt
        
        if [[ -f "requirements-test.txt" ]]; then
            python3 -m pip install -r requirements-test.txt
        fi
    fi
    
    # Install Node.js dependencies
    if [[ -f "package.json" ]]; then
        log "INFO" "Installing Node.js dependencies..."
        npm install --production
    fi
    
    # Install 11ty and Svelte if needed
    if [[ -d "src/pages" ]] || [[ -d "src/components" ]]; then
        log "INFO" "Installing static site generator dependencies..."
        npm install @11ty/eleventy svelte --save-dev
    fi
    
    log "SUCCESS" "Dependencies installed"
}

run_tests() {
    log "INFO" "Running test suite..."
    
    cd "$PROJECT_ROOT"
    
    # Run Python tests
    if command -v pytest >/dev/null 2>&1; then
        log "INFO" "Running Python tests..."
        python -m pytest tests/ -v --tb=short || {
            log "WARN" "Some Python tests failed - check manually"
        }
    fi
    
    # Run batch validation tests
    local batch_tests=(193 192 191 190 189 188)
    for batch in "${batch_tests[@]}"; do
        local test_file="test_batch_${batch}_*.py"
        if ls $test_file 1> /dev/null 2>&1; then
            log "INFO" "Running Batch $batch tests..."
            python test_batch_${batch}_*.py || {
                log "WARN" "Batch $batch tests had issues - check manually"
            }
        fi
    done
    
    # Run build validation
    if [[ -f "Makefile" ]]; then
        log "INFO" "Running make validation..."
        make validate || {
            log "WARN" "Make validation had issues - check manually"
        }
    fi
    
    log "SUCCESS" "Test suite completed"
}

build_static_assets() {
    log "INFO" "Building static assets..."
    
    cd "$PROJECT_ROOT"
    
    # Build 11ty static site
    if [[ -d "src/pages" ]]; then
        log "INFO" "Building 11ty static site..."
        npx @11ty/eleventy --output="$BUILD_DIR/site"
    fi
    
    # Build Svelte components
    if [[ -d "src/components" ]]; then
        log "INFO" "Building Svelte components..."
        # Note: This would require a proper Svelte build configuration
        # For now, we'll just copy the components
        mkdir -p "$BUILD_DIR/components"
        cp -r src/components/* "$BUILD_DIR/components/"
    fi
    
    # Copy static assets
    local asset_dirs=("assets" "public" "static")
    for dir in "${asset_dirs[@]}"; do
        if [[ -d "$PROJECT_ROOT/$dir" ]]; then
            log "INFO" "Copying assets from $dir..."
            cp -r "$PROJECT_ROOT/$dir"/* "$BUILD_DIR/" 2>/dev/null || true
        fi
    done
    
    log "SUCCESS" "Static assets built"
}

inject_analytics() {
    if [[ "$ANALYTICS_ENABLED" == "true" ]]; then
        log "INFO" "Injecting Google Analytics and Search Console..."
        
        # Load analytics configuration
        local gtm_id=""
        local gsc_verification=""
        
        if [[ -f "$DEPLOY_CONFIG" ]] && command -v jq >/dev/null 2>&1; then
            gtm_id=$(jq -r '.analytics.google_tag_manager.container_id' "$DEPLOY_CONFIG" 2>/dev/null || echo "")
            gsc_verification=$(jq -r '.analytics.search_console.verification_code' "$DEPLOY_CONFIG" 2>/dev/null || echo "")
        fi
        
        # Find HTML files to inject analytics
        if [[ -d "$BUILD_DIR" ]]; then
            find "$BUILD_DIR" -name "*.html" -type f | while read -r html_file; do
                log "INFO" "Processing: $(basename "$html_file")"
                
                # Inject Google Tag Manager (Head)
                if [[ -n "$gtm_id" ]]; then
                    local gtm_head="<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','$gtm_id');</script>
<!-- End Google Tag Manager -->"
                    
                    sed -i "s|<head>|<head>\n$gtm_head|g" "$html_file" 2>/dev/null || true
                fi
                
                # Inject Google Tag Manager (Body)
                if [[ -n "$gtm_id" ]]; then
                    local gtm_body="<!-- Google Tag Manager (noscript) -->
<noscript><iframe src=\"https://www.googletagmanager.com/ns.html?id=$gtm_id\"
height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->"
                    
                    sed -i "s|<body>|<body>\n$gtm_body|g" "$html_file" 2>/dev/null || true
                fi
                
                # Inject Search Console verification
                if [[ -n "$gsc_verification" ]]; then
                    local gsc_meta="<meta name=\"google-site-verification\" content=\"$gsc_verification\" />"
                    sed -i "s|</head>|$gsc_meta\n</head>|g" "$html_file" 2>/dev/null || true
                fi
            done
        fi
        
        log "SUCCESS" "Analytics injection completed"
    else
        log "INFO" "Analytics injection disabled"
    fi
}

optimize_assets() {
    log "INFO" "Optimizing assets for production..."
    
    if [[ -d "$BUILD_DIR" ]]; then
        # Minify CSS files
        if command -v cleancss >/dev/null 2>&1; then
            find "$BUILD_DIR" -name "*.css" -type f | while read -r css_file; do
                cleancss -o "$css_file" "$css_file" 2>/dev/null || true
            done
            log "INFO" "CSS files minified"
        fi
        
        # Minify JavaScript files
        if command -v uglifyjs >/dev/null 2>&1; then
            find "$BUILD_DIR" -name "*.js" -not -path "*/node_modules/*" -type f | while read -r js_file; do
                uglifyjs "$js_file" -o "$js_file" 2>/dev/null || true
            done
            log "INFO" "JavaScript files minified"
        fi
        
        # Optimize images
        if command -v optipng >/dev/null 2>&1; then
            find "$BUILD_DIR" -name "*.png" -type f | while read -r png_file; do
                optipng -quiet "$png_file" 2>/dev/null || true
            done
            log "INFO" "PNG images optimized"
        fi
        
        # Gzip pre-compression
        find "$BUILD_DIR" -type f \( -name "*.html" -o -name "*.css" -o -name "*.js" -o -name "*.json" \) | while read -r file; do
            gzip -9 -c "$file" > "$file.gz" 2>/dev/null || true
        done
        log "INFO" "Gzip pre-compression completed"
    fi
    
    log "SUCCESS" "Asset optimization completed"
}

generate_sitemap() {
    log "INFO" "Generating sitemap..."
    
    local sitemap_file="$BUILD_DIR/sitemap.xml"
    local base_url="https://$DOMAIN"
    
    cat > "$sitemap_file" << EOF
<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.sitemaps.org/schemas/sitemap/0.9
        http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd">
EOF
    
    # Add main pages
    local pages=(
        ""
        "heroics/"
        "loot/"
        "builds/"
        "quests/"
        "tools/"
        "api/"
        "contribute/"
    )
    
    for page in "${pages[@]}"; do
        echo "  <url>" >> "$sitemap_file"
        echo "    <loc>$base_url/$page</loc>" >> "$sitemap_file"
        echo "    <lastmod>$(date +%Y-%m-%d)</lastmod>" >> "$sitemap_file"
        echo "    <changefreq>weekly</changefreq>" >> "$sitemap_file"
        echo "    <priority>0.8</priority>" >> "$sitemap_file"
        echo "  </url>" >> "$sitemap_file"
    done
    
    # Add heroic pages
    if [[ -f "data/heroics/heroics_index.yml" ]]; then
        local heroics=($(python3 -c "
import yaml
try:
    with open('data/heroics/heroics_index.yml', 'r') as f:
        data = yaml.safe_load(f)
        for heroic_id in data.get('heroics', {}).keys():
            print(heroic_id)
except: pass
" 2>/dev/null))
        
        for heroic in "${heroics[@]}"; do
            echo "  <url>" >> "$sitemap_file"
            echo "    <loc>$base_url/heroics/$heroic/</loc>" >> "$sitemap_file"
            echo "    <lastmod>$(date +%Y-%m-%d)</lastmod>" >> "$sitemap_file"
            echo "    <changefreq>monthly</changefreq>" >> "$sitemap_file"
            echo "    <priority>0.7</priority>" >> "$sitemap_file"
            echo "  </url>" >> "$sitemap_file"
        done
    fi
    
    echo "</urlset>" >> "$sitemap_file"
    
    # Generate robots.txt
    cat > "$BUILD_DIR/robots.txt" << EOF
User-agent: *
Allow: /

Sitemap: $base_url/sitemap.xml
EOF
    
    log "SUCCESS" "Sitemap and robots.txt generated"
}

setup_security_headers() {
    log "INFO" "Setting up security headers..."
    
    # Create .htaccess for Apache
    cat > "$BUILD_DIR/.htaccess" << 'EOF'
# Security Headers
Header always set X-Content-Type-Options nosniff
Header always set X-Frame-Options DENY
Header always set X-XSS-Protection "1; mode=block"
Header always set Referrer-Policy "strict-origin-when-cross-origin"
Header always set Permissions-Policy "camera=(), microphone=(), geolocation=()"

# HSTS (if using HTTPS)
Header always set Strict-Transport-Security "max-age=31536000; includeSubDomains; preload"

# Content Security Policy
Header always set Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline' https://www.googletagmanager.com https://www.google-analytics.com; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self' https:; connect-src 'self' https:; frame-src 'self' https://www.google.com;"

# Cache Control
<FilesMatch "\.(css|js|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$">
    Header set Cache-Control "public, max-age=31536000"
</FilesMatch>

<FilesMatch "\.(html|htm)$">
    Header set Cache-Control "public, max-age=3600"
</FilesMatch>

# Gzip Compression
<IfModule mod_deflate.c>
    AddOutputFilterByType DEFLATE text/plain
    AddOutputFilterByType DEFLATE text/html
    AddOutputFilterByType DEFLATE text/xml
    AddOutputFilterByType DEFLATE text/css
    AddOutputFilterByType DEFLATE application/xml
    AddOutputFilterByType DEFLATE application/xhtml+xml
    AddOutputFilterByType DEFLATE application/rss+xml
    AddOutputFilterByType DEFLATE application/javascript
    AddOutputFilterByType DEFLATE application/x-javascript
    AddOutputFilterByType DEFLATE application/json
</IfModule>
EOF
    
    # Create _headers file for Netlify/modern hosting
    cat > "$BUILD_DIR/_headers" << 'EOF'
/*
  X-Content-Type-Options: nosniff
  X-Frame-Options: DENY
  X-XSS-Protection: 1; mode=block
  Referrer-Policy: strict-origin-when-cross-origin
  Permissions-Policy: camera=(), microphone=(), geolocation=()

/assets/*
  Cache-Control: public, max-age=31536000, immutable

/*.html
  Cache-Control: public, max-age=3600
EOF
    
    log "SUCCESS" "Security headers configured"
}

purge_cdn() {
    if [[ "$CDN_ENABLED" == "true" ]]; then
        log "INFO" "Purging CDN cache..."
        
        local cdn_provider=""
        local cdn_config=""
        
        if [[ -f "$DEPLOY_CONFIG" ]] && command -v jq >/dev/null 2>&1; then
            cdn_provider=$(jq -r '.cdn.provider' "$DEPLOY_CONFIG" 2>/dev/null || echo "")
            cdn_config=$(jq -r '.cdn' "$DEPLOY_CONFIG" 2>/dev/null || echo "{}")
        fi
        
        case "$cdn_provider" in
            "cloudflare")
                local cf_zone_id=$(echo "$cdn_config" | jq -r '.cloudflare.zone_id' 2>/dev/null || echo "")
                local cf_api_token=$(echo "$cdn_config" | jq -r '.cloudflare.api_token' 2>/dev/null || echo "")
                
                if [[ -n "$cf_zone_id" && -n "$cf_api_token" ]]; then
                    curl -X POST "https://api.cloudflare.com/client/v4/zones/$cf_zone_id/purge_cache" \
                         -H "Authorization: Bearer $cf_api_token" \
                         -H "Content-Type: application/json" \
                         --data '{"purge_everything":true}' \
                         --silent --output /dev/null || {
                        log "WARN" "CDN purge failed"
                    }
                    log "SUCCESS" "Cloudflare CDN cache purged"
                else
                    log "WARN" "Cloudflare CDN configuration incomplete"
                fi
                ;;
            "fastly")
                local fastly_service_id=$(echo "$cdn_config" | jq -r '.fastly.service_id' 2>/dev/null || echo "")
                local fastly_api_token=$(echo "$cdn_config" | jq -r '.fastly.api_token' 2>/dev/null || echo "")
                
                if [[ -n "$fastly_service_id" && -n "$fastly_api_token" ]]; then
                    curl -X POST "https://api.fastly.com/service/$fastly_service_id/purge_all" \
                         -H "Fastly-Token: $fastly_api_token" \
                         --silent --output /dev/null || {
                        log "WARN" "CDN purge failed"
                    }
                    log "SUCCESS" "Fastly CDN cache purged"
                else
                    log "WARN" "Fastly CDN configuration incomplete"
                fi
                ;;
            *)
                log "INFO" "No CDN provider configured or unsupported provider"
                ;;
        esac
    else
        log "INFO" "CDN purge disabled"
    fi
}

send_discord_notification() {
    if [[ -n "$DISCORD_WEBHOOK_URL" ]]; then
        log "INFO" "Sending Discord launch notification..."
        
        local embed_json=$(cat << EOF
{
  "embeds": [
    {
      "title": "ðŸš€ MorningStar Public Launch",
      "description": "The MorningStar project has successfully launched to production!",
      "color": 65280,
      "fields": [
        {
          "name": "ðŸŒ Domain",
          "value": "$DOMAIN",
          "inline": true
        },
        {
          "name": "ðŸ“… Launch Date",
          "value": "$LAUNCH_DATE",
          "inline": true
        },
        {
          "name": "ðŸ”§ Script Version",
          "value": "$SCRIPT_VERSION",
          "inline": true
        },
        {
          "name": "ðŸ“Š Analytics",
          "value": "$ANALYTICS_ENABLED",
          "inline": true
        },
        {
          "name": "ðŸš€ CDN",
          "value": "$CDN_ENABLED",
          "inline": true
        },
        {
          "name": "ðŸ“ Backup Location",
          "value": "$(basename "$BACKUP_DIR")",
          "inline": false
        }
      ],
      "timestamp": "$(date -Iseconds)",
      "footer": {
        "text": "MorningStar Launch System"
      }
    }
  ]
}
EOF
)
        
        curl -H "Content-Type: application/json" \
             -d "$embed_json" \
             "$DISCORD_WEBHOOK_URL" \
             --silent --output /dev/null || {
            log "WARN" "Discord notification failed"
        }
        
        log "SUCCESS" "Discord notification sent"
    else
        log "INFO" "Discord webhook not configured"
    fi
}

validate_deployment() {
    log "INFO" "Validating deployment..."
    
    local validation_errors=()
    
    # Check build directory
    if [[ ! -d "$BUILD_DIR" ]]; then
        validation_errors+=("Build directory missing: $BUILD_DIR")
    fi
    
    # Check critical files
    local critical_files=(
        "$BUILD_DIR/index.html"
        "$BUILD_DIR/sitemap.xml"
        "$BUILD_DIR/robots.txt"
    )
    
    for file in "${critical_files[@]}"; do
        if [[ ! -f "$file" ]]; then
            validation_errors+=("Critical file missing: $(basename "$file")")
        fi
    done
    
    # Check analytics injection (if enabled)
    if [[ "$ANALYTICS_ENABLED" == "true" && -f "$BUILD_DIR/index.html" ]]; then
        if ! grep -q "googletagmanager.com" "$BUILD_DIR/index.html" 2>/dev/null; then
            validation_errors+=("Google Tag Manager not found in HTML")
        fi
    fi
    
    # Check security headers
    if [[ ! -f "$BUILD_DIR/.htaccess" && ! -f "$BUILD_DIR/_headers" ]]; then
        validation_errors+=("Security headers configuration missing")
    fi
    
    if [[ ${#validation_errors[@]} -ne 0 ]]; then
        log "ERROR" "Deployment validation failed:"
        for error in "${validation_errors[@]}"; do
            log "ERROR" "  - $error"
        done
        return 1
    fi
    
    log "SUCCESS" "Deployment validation passed"
    return 0
}

cleanup_temp_files() {
    log "INFO" "Cleaning up temporary files..."
    
    # Remove temporary build files
    find "$BUILD_DIR" -name "*.tmp" -delete 2>/dev/null || true
    find "$BUILD_DIR" -name ".DS_Store" -delete 2>/dev/null || true
    find "$BUILD_DIR" -name "Thumbs.db" -delete 2>/dev/null || true
    
    # Remove development files from build
    local dev_files=(
        "*.md"
        "*.py"
        "*.sh"
        ".git*"
        "node_modules"
        "__pycache__"
        "*.pyc"
        "tests"
        "test_*"
        "demo_*"
    )
    
    for pattern in "${dev_files[@]}"; do
        find "$BUILD_DIR" -name "$pattern" -exec rm -rf {} + 2>/dev/null || true
    done
    
    log "SUCCESS" "Cleanup completed"
}

generate_deployment_manifest() {
    log "INFO" "Generating deployment manifest..."
    
    local manifest_file="$BUILD_DIR/DEPLOYMENT_MANIFEST.json"
    
    cat > "$manifest_file" << EOF
{
  "deployment": {
    "timestamp": "$LAUNCH_DATE",
    "script_version": "$SCRIPT_VERSION",
    "domain": "$DOMAIN",
    "analytics_enabled": $ANALYTICS_ENABLED,
    "cdn_enabled": $CDN_ENABLED
  },
  "project": {
    "name": "MorningStar",
    "description": "Star Wars Galaxies Database & MS11 Automation Suite",
    "version": "$(cat VERSION 2>/dev/null || echo "1.0.0")",
    "git_commit": "$(cd "$PROJECT_ROOT" && git rev-parse HEAD 2>/dev/null || echo "unknown")"
  },
  "build": {
    "build_time": "$LAUNCH_DATE",
    "build_directory": "$(basename "$BUILD_DIR")",
    "backup_directory": "$(basename "$BACKUP_DIR")"
  },
  "features": {
    "swgdb": true,
    "ms11_automation": true,
    "heroic_guides": true,
    "loot_tracking": true,
    "build_showcase": true,
    "discord_integration": true,
    "analytics": $ANALYTICS_ENABLED
  }
}
EOF
    
    log "SUCCESS" "Deployment manifest created"
}

print_launch_summary() {
    echo ""
    echo -e "${GREEN}============================================================${NC}"
    echo -e "${GREEN}ðŸŽ‰ LAUNCH SUCCESSFUL! ðŸŽ‰${NC}"
    echo -e "${GREEN}============================================================${NC}"
    echo ""
    echo -e "${WHITE}Project:${NC} MorningStar (SWGDB + MS11)"
    echo -e "${WHITE}Domain:${NC} $DOMAIN"
    echo -e "${WHITE}Launch Date:${NC} $LAUNCH_DATE"
    echo -e "${WHITE}Build Directory:${NC} $BUILD_DIR"
    echo -e "${WHITE}Backup Location:${NC} $BACKUP_DIR"
    echo -e "${WHITE}Log File:${NC} $LOG_FILE"
    echo ""
    echo -e "${BLUE}ðŸ“Š Launch Statistics:${NC}"
    echo -e "  Analytics Enabled: $ANALYTICS_ENABLED"
    echo -e "  CDN Enabled: $CDN_ENABLED"
    echo -e "  Files Built: $(find "$BUILD_DIR" -type f | wc -l)"
    echo -e "  Build Size: $(du -sh "$BUILD_DIR" | cut -f1)"
    echo ""
    echo -e "${BLUE}ðŸ”— Next Steps:${NC}"
    echo -e "  1. Upload $BUILD_DIR contents to your web server"
    echo -e "  2. Configure DNS to point to your hosting provider"
    echo -e "  3. Set up SSL certificate (Let's Encrypt recommended)"
    echo -e "  4. Test all functionality on the live domain"
    echo -e "  5. Monitor logs and analytics for issues"
    echo ""
    echo -e "${BLUE}ðŸ“š Documentation:${NC}"
    echo -e "  â€¢ README.md - Project overview and setup"
    echo -e "  â€¢ DEPLOYMENT_MANIFEST.json - Build information"
    echo -e "  â€¢ Batch implementation summaries - Feature details"
    echo ""
    echo -e "${GREEN}ðŸš€ Welcome to production! ðŸš€${NC}"
    echo ""
}

# Main execution flow
main() {
    print_header
    
    # Ensure we're in the right directory
    cd "$PROJECT_ROOT"
    
    # Pre-flight checks
    check_prerequisites
    validate_project_structure
    
    # Preparation phase
    create_required_directories
    backup_current_state
    
    # Build phase
    install_dependencies
    run_tests
    build_static_assets
    
    # Enhancement phase
    inject_analytics
    optimize_assets
    generate_sitemap
    setup_security_headers
    
    # Deployment phase
    purge_cdn
    generate_deployment_manifest
    
    # Validation phase
    if ! validate_deployment; then
        log "ERROR" "Deployment validation failed - aborting launch"
        exit 1
    fi
    
    # Cleanup phase
    cleanup_temp_files
    
    # Notification phase
    send_discord_notification
    
    # Success!
    print_launch_summary
    
    log "SUCCESS" "ðŸš€ Launch completed successfully!"
}

# Error handling
trap 'log "ERROR" "Script failed at line $LINENO. Exit code: $?"' ERR

# Script execution
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi