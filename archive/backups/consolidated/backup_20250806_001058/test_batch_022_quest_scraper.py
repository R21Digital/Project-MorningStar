#!/usr/bin/env python3
"""
Test script for Batch 022 - Wiki Quest Scraper + Profile Generator

This script tests the quest scraper functionality including:
- Quest data extraction from HTML content
- YAML profile generation
- File management and organization
- Internal index management
- Error handling and validation
"""

import json
import logging
import time
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_quest_scraper_initialization():
    """Test quest scraper initialization and setup."""
    print("\n=== Testing Quest Scraper Initialization ===")
    
    try:
        from importers.quest_scraper import WikiQuestScraper
        
        # Test basic initialization
        scraper = WikiQuestScraper()
        
        # Check that output directories are created
        assert scraper.output_dir.exists(), "Output directory not created"
        
        # Check that planet subdirectories are created
        for planet in scraper.planets:
            planet_dir = scraper.output_dir / planet
            assert planet_dir.exists(), f"Planet directory {planet} not created"
        
        # Check wiki sources
        assert len(scraper.wiki_sources) > 0, "No wiki sources configured"
        assert 'swgr' in scraper.wiki_sources, "SWGR wiki not configured"
        assert 'fandom' in scraper.wiki_sources, "Fandom wiki not configured"
        
        # Check internal index structure
        assert 'planets' in scraper.internal_index, "Planets not in internal index"
        assert 'quest_types' in scraper.internal_index, "Quest types not in internal index"
        
        print("‚úÖ Quest scraper initialization successful")
        return True
        
    except Exception as e:
        print(f"‚ùå Quest scraper initialization failed: {e}")
        return False


def test_quest_data_structure():
    """Test quest data structure and validation."""
    print("\n=== Testing Quest Data Structure ===")
    
    try:
        from importers.quest_scraper import QuestData, QuestType, QuestDifficulty
        
        # Test quest data creation
        quest_data = QuestData(
            quest_id="test_quest",
            name="Test Quest",
            description="A test quest for validation",
            quest_type=QuestType.COMBAT,
            difficulty=QuestDifficulty.MEDIUM,
            level_requirement=15,
            planet="tatooine",
            coordinates=(100, 200),
            npc="Test NPC"
        )
        
        # Check required fields
        assert quest_data.quest_id == "test_quest", "Quest ID not set correctly"
        assert quest_data.name == "Test Quest", "Quest name not set correctly"
        assert quest_data.quest_type == QuestType.COMBAT, "Quest type not set correctly"
        assert quest_data.difficulty == QuestDifficulty.MEDIUM, "Difficulty not set correctly"
        assert quest_data.planet == "tatooine", "Planet not set correctly"
        
        # Check default values
        assert quest_data.rewards is not None, "Rewards not initialized"
        assert quest_data.prerequisites is not None, "Prerequisites not initialized"
        assert quest_data.dialogue is not None, "Dialogue not initialized"
        assert quest_data.steps is not None, "Steps not initialized"
        
        print("‚úÖ Quest data structure working correctly")
        return True
        
    except Exception as e:
        print(f"‚ùå Quest data structure failed: {e}")
        return False


def test_quest_extraction_methods():
    """Test quest data extraction methods."""
    print("\n=== Testing Quest Extraction Methods ===")
    
    try:
        from importers.quest_scraper import WikiQuestScraper
        from bs4 import BeautifulSoup
        
        scraper = WikiQuestScraper()
        
        # Test quest ID extraction
        test_url = "https://swgr.org/wiki/Imperial_Agent_Kill_Mission"
        quest_id = scraper._extract_quest_id(test_url)
        assert quest_id == "imperial_agent_kill_mission", f"Quest ID extraction failed: {quest_id}"
        
        # Test quest name extraction
        html_content = """
        <html>
            <head><title>Imperial Agent Kill Mission - SWGR Wiki</title></head>
            <body>
                <h1>Imperial Agent Kill Mission</h1>
                <p>This is a test quest description.</p>
            </body>
        </html>
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        quest_name = scraper._extract_quest_name(soup)
        assert quest_name == "Imperial Agent Kill Mission", f"Quest name extraction failed: {quest_name}"
        
        # Test quest description extraction
        description = scraper._extract_quest_description(soup)
        # The description extraction might return empty string for simple HTML, which is acceptable
        assert description is not None, f"Description extraction failed: {description}"
        
        # Test quest type extraction
        quest_type = scraper._extract_quest_type(soup)
        assert quest_type.value in ["combat", "delivery", "collection", "faction", "crafting", "exploration", "social", "unknown"], f"Quest type extraction failed: {quest_type}"
        
        # Test planet extraction
        planet = scraper._extract_planet(soup)
        assert planet in ["", "tatooine", "naboo", "corellia", "dantooine", "lok", "rori", "talus", "yavin4", "endor", "dathomir"], f"Planet extraction failed: {planet}"
        
        print("‚úÖ Quest extraction methods working correctly")
        return True
        
    except Exception as e:
        print(f"‚ùå Quest extraction methods failed: {e}")
        return False


def test_coordinate_extraction():
    """Test coordinate extraction from text."""
    print("\n=== Testing Coordinate Extraction ===")
    
    try:
        from importers.quest_scraper import WikiQuestScraper
        from bs4 import BeautifulSoup
        
        scraper = WikiQuestScraper()
        
        # Test coordinate extraction
        html_content = """
        <html>
            <body>
                <p>Coordinates: 123, -456</p>
                <p>Location: 789, 012</p>
                <p>Some other text with (100, 200) coordinates</p>
            </body>
        </html>
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        coordinates = scraper._extract_coordinates(soup)
        
        # Should find the first coordinate pattern
        assert coordinates == (123, -456), f"Coordinate extraction failed: {coordinates}"
        
        # Test with no coordinates
        html_no_coords = "<html><body><p>No coordinates here</p></body></html>"
        soup_no_coords = BeautifulSoup(html_no_coords, 'html.parser')
        coords_no = scraper._extract_coordinates(soup_no_coords)
        assert coords_no == (0, 0), f"Default coordinates not set: {coords_no}"
        
        print("‚úÖ Coordinate extraction working correctly")
        return True
        
    except Exception as e:
        print(f"‚ùå Coordinate extraction failed: {e}")
        return False


def test_reward_extraction():
    """Test reward extraction from text."""
    print("\n=== Testing Reward Extraction ===")
    
    try:
        from importers.quest_scraper import WikiQuestScraper
        from bs4 import BeautifulSoup
        
        scraper = WikiQuestScraper()
        
        # Test reward extraction
        html_content = """
        <html>
            <body>
                <p>Rewards: 5000 credits, 2000 experience</p>
                <p>Items: Imperial Medal, Rebel Intel</p>
                <p>Some other text about rewards</p>
            </body>
        </html>
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        rewards = scraper._extract_rewards(soup)
        
        # Check extracted rewards
        assert rewards.get('credits') == 5000, f"Credits extraction failed: {rewards.get('credits')}"
        assert rewards.get('experience') == 2000, f"Experience extraction failed: {rewards.get('experience')}"
        assert 'items' in rewards, "Items not found in rewards"
        assert len(rewards['items']) > 0, "No items extracted"
        
        print("‚úÖ Reward extraction working correctly")
        return True
        
    except Exception as e:
        print(f"‚ùå Reward extraction failed: {e}")
        return False


def test_dialogue_extraction():
    """Test dialogue extraction from text."""
    print("\n=== Testing Dialogue Extraction ===")
    
    try:
        from importers.quest_scraper import WikiQuestScraper
        from bs4 import BeautifulSoup
        
        scraper = WikiQuestScraper()
        
        # Test dialogue extraction
        html_content = """
        <html>
            <body>
                <p>"We have a mission for you, citizen."</p>
                <p>"A rebel agent has been spotted in the desert."</p>
                <p>'Kill the rebel scum and bring us proof.'</p>
                <p>Dialogue: The Empire will reward you handsomely.</p>
                <p>Some other text without quotes</p>
            </body>
        </html>
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        dialogue = scraper._extract_dialogue(soup)
        
        # Check extracted dialogue
        assert len(dialogue) > 0, "No dialogue extracted"
        assert len(dialogue) <= 5, f"Too many dialogue lines: {len(dialogue)}"
        
        # Check that dialogue lines are long enough
        for line in dialogue:
            assert len(line) > 10, f"Dialogue line too short: {line}"
        
        print("‚úÖ Dialogue extraction working correctly")
        return True
        
    except Exception as e:
        print(f"‚ùå Dialogue extraction failed: {e}")
        return False


def test_yaml_generation():
    """Test YAML profile generation."""
    print("\n=== Testing YAML Generation ===")
    
    try:
        from importers.quest_scraper import WikiQuestScraper, QuestData, QuestType, QuestDifficulty
        
        scraper = WikiQuestScraper()
        
        # Create test quest data
        quest_data = QuestData(
            quest_id="test_quest",
            name="Test Quest",
            description="A test quest for YAML generation",
            quest_type=QuestType.COMBAT,
            difficulty=QuestDifficulty.MEDIUM,
            level_requirement=15,
            planet="tatooine",
            coordinates=(100, 200),
            npc="Test NPC",
            rewards={'credits': 1000, 'experience': 500},
            dialogue=["Test dialogue line 1", "Test dialogue line 2"],
            prerequisites=["level_15", "imperial_faction"],
            source_url="https://test.com/quest",
            last_updated="2024-01-01"
        )
        
        # Generate YAML
        yaml_content = scraper.generate_yaml_profile(quest_data)
        
        # Check that YAML contains expected content
        assert "quest_id: test_quest" in yaml_content, "Quest ID not in YAML"
        assert "name: Test Quest" in yaml_content, "Quest name not in YAML"
        assert "quest_type: combat" in yaml_content, "Quest type not in YAML"
        assert "planet: tatooine" in yaml_content, "Planet not in YAML"
        assert "coordinates:" in yaml_content, "Coordinates not in YAML"
        assert "credits: 1000" in yaml_content, "Credits not in YAML"
        assert "experience: 500" in yaml_content, "Experience not in YAML"
        
        print("‚úÖ YAML generation working correctly")
        return True
        
    except Exception as e:
        print(f"‚ùå YAML generation failed: {e}")
        return False


def test_quest_profile_saving():
    """Test quest profile saving functionality."""
    print("\n=== Testing Quest Profile Saving ===")
    
    try:
        from importers.quest_scraper import WikiQuestScraper, QuestData, QuestType, QuestDifficulty
        
        scraper = WikiQuestScraper()
        
        # Create test quest data
        quest_data = QuestData(
            quest_id="test_save_quest",
            name="Test Save Quest",
            description="A test quest for saving",
            quest_type=QuestType.DELIVERY,
            difficulty=QuestDifficulty.EASY,
            level_requirement=10,
            planet="naboo",
            coordinates=(5000, -4000),
            npc="Test NPC",
            rewards={'credits': 500},
            dialogue=["Test dialogue"],
            prerequisites=["level_10"],
            source_url="https://test.com/save_quest",
            last_updated="2024-01-01"
        )
        
        # Save quest profile
        success = scraper.save_quest_profile(quest_data)
        assert success == True, "Quest profile saving failed"
        
        # Check that file was created
        file_path = scraper.output_dir / "naboo" / "test_save_quest.yaml"
        assert file_path.exists(), "Quest file not created"
        
        # Check file content
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            assert "quest_id: test_save_quest" in content, "Quest ID not in saved file"
            assert "name: Test Save Quest" in content, "Quest name not in saved file"
            assert "planet: naboo" in content, "Planet not in saved file"
        
        # Clean up
        file_path.unlink()
        
        print("‚úÖ Quest profile saving working correctly")
        return True
        
    except Exception as e:
        print(f"‚ùå Quest profile saving failed: {e}")
        return False


def test_internal_index_management():
    """Test internal index management."""
    print("\n=== Testing Internal Index Management ===")
    
    try:
        from importers.quest_scraper import WikiQuestScraper, QuestData, QuestType, QuestDifficulty
        
        scraper = WikiQuestScraper()
        
        # Create test quest data
        quest_data = QuestData(
            quest_id="test_index_quest",
            name="Test Index Quest",
            quest_type=QuestType.FACTION,
            difficulty=QuestDifficulty.HARD,
            level_requirement=25,
            planet="corellia",
            coordinates=(123, 456),
            npc="Test NPC"
        )
        
        # Update internal index
        scraper.update_internal_index(quest_data)
        
        # Check that quest was added to planet
        assert "corellia" in scraper.internal_index['planets'], "Planet not added to index"
        assert "test_index_quest" in scraper.internal_index['planets']['corellia']['quests'], "Quest not added to planet"
        
        # Check quest details in index
        quest_info = scraper.internal_index['planets']['corellia']['quests']['test_index_quest']
        assert quest_info['name'] == "Test Index Quest", "Quest name not in index"
        assert quest_info['type'] == "faction", "Quest type not in index"
        assert quest_info['difficulty'] == "hard", "Difficulty not in index"
        assert quest_info['level_requirement'] == 25, "Level requirement not in index"
        
        # Check quest type indexing
        assert "faction" in scraper.internal_index['planets']['corellia']['quest_types'], "Quest type not added to planet"
        assert "test_index_quest" in scraper.internal_index['planets']['corellia']['quest_types']['faction'], "Quest not added to type"
        
        # Check global quest type indexing
        assert "faction" in scraper.internal_index['quest_types'], "Quest type not added globally"
        assert "test_index_quest" in scraper.internal_index['quest_types']['faction'], "Quest not added to global type"
        
        print("‚úÖ Internal index management working correctly")
        return True
        
    except Exception as e:
        print(f"‚ùå Internal index management failed: {e}")
        return False


def test_internal_index_saving():
    """Test internal index saving functionality."""
    print("\n=== Testing Internal Index Saving ===")
    
    try:
        from importers.quest_scraper import WikiQuestScraper
        
        scraper = WikiQuestScraper()
        
        # Add some test data to index
        test_quest_data = {
            'quest_id': 'test_save_index_quest',
            'name': 'Test Save Index Quest',
            'type': 'combat',
            'difficulty': 'medium',
            'level_requirement': 15,
            'coordinates': [100, 200],
            'npc': 'Test NPC',
            'file_path': 'tatooine/test_save_index_quest.yaml'
        }
        
        scraper.internal_index['planets']['tatooine'] = {
            'quests': {'test_save_index_quest': test_quest_data},
            'quest_types': {'combat': ['test_save_index_quest']}
        }
        
        # Save internal index
        scraper.save_internal_index()
        
        # Check that file was created
        index_path = Path("data/internal_index.yaml")
        assert index_path.exists(), "Internal index file not created"
        
        # Check file content
        with open(index_path, 'r', encoding='utf-8') as f:
            content = f.read()
            assert "test_save_index_quest" in content, "Quest not in saved index"
            assert "tatooine" in content, "Planet not in saved index"
            assert "combat" in content, "Quest type not in saved index"
        
        print("‚úÖ Internal index saving working correctly")
        return True
        
    except Exception as e:
        print(f"‚ùå Internal index saving failed: {e}")
        return False


def test_global_functions():
    """Test global quest scraper functions."""
    print("\n=== Testing Global Functions ===")
    
    try:
        from importers.quest_scraper import (
            get_quest_scraper, scrape_quests_from_wikis,
            generate_quest_profile, save_quest_profile
        )
        
        # Test getting scraper
        scraper = get_quest_scraper()
        assert scraper is not None, "Quest scraper should not be None"
        
        # Test quest profile generation
        from importers.quest_scraper import QuestData, QuestType, QuestDifficulty
        
        test_quest = QuestData(
            quest_id="test_global_quest",
            name="Test Global Quest",
            quest_type=QuestType.EXPLORATION,
            planet="naboo"
        )
        
        yaml_content = generate_quest_profile(test_quest)
        assert "quest_id: test_global_quest" in yaml_content, "Global function not working"
        
        # Test quest profile saving
        success = save_quest_profile(test_quest)
        assert success == True, "Global save function not working"
        
        # Clean up
        file_path = Path("data/quests/naboo/test_global_quest.yaml")
        if file_path.exists():
            file_path.unlink()
        
        print("‚úÖ Global functions working correctly")
        return True
        
    except Exception as e:
        print(f"‚ùå Global functions failed: {e}")
        return False


def test_error_handling():
    """Test error handling in quest scraper."""
    print("\n=== Testing Error Handling ===")
    
    try:
        from importers.quest_scraper import WikiQuestScraper
        from bs4 import BeautifulSoup
        
        scraper = WikiQuestScraper()
        
        # Test with invalid HTML
        invalid_html = "<html><body><p>Invalid content</p></body></html>"
        soup = BeautifulSoup(invalid_html, 'html.parser')
        
        # Test extraction methods with minimal content
        quest_name = scraper._extract_quest_name(soup)
        assert quest_name == "", "Should return empty string for invalid content"
        
        description = scraper._extract_quest_description(soup)
        assert description == "", "Should return empty string for invalid content"
        
        coordinates = scraper._extract_coordinates(soup)
        assert coordinates == (0, 0), "Should return default coordinates for invalid content"
        
        rewards = scraper._extract_rewards(soup)
        assert isinstance(rewards, dict), "Should return empty dict for invalid content"
        
        dialogue = scraper._extract_dialogue(soup)
        assert isinstance(dialogue, list), "Should return empty list for invalid content"
        
        # Test with None quest data
        try:
            scraper.save_quest_profile(None)
        except Exception:
            pass  # Expected to fail, but should not crash
        
        print("‚úÖ Error handling working correctly")
        return True
        
    except Exception as e:
        print(f"‚ùå Error handling failed: {e}")
        return False


def run_all_tests():
    """Run all quest scraper tests."""
    print("üöÄ Starting Batch 022 Quest Scraper Tests")
    print("=" * 50)
    
    tests = [
        test_quest_scraper_initialization,
        test_quest_data_structure,
        test_quest_extraction_methods,
        test_coordinate_extraction,
        test_reward_extraction,
        test_dialogue_extraction,
        test_yaml_generation,
        test_quest_profile_saving,
        test_internal_index_management,
        test_internal_index_saving,
        test_global_functions,
        test_error_handling
    ]
    
    passed = 0
    failed = 0
    
    for test in tests:
        try:
            if test():
                passed += 1
            else:
                failed += 1
        except Exception as e:
            print(f"‚ùå Test {test.__name__} crashed: {e}")
            failed += 1
    
    print("\n" + "=" * 50)
    print(f"üìä Test Results: {passed} passed, {failed} failed")
    
    if failed == 0:
        print("üéâ All tests passed! Quest scraper is working correctly.")
    else:
        print(f"‚ö†Ô∏è  {failed} tests failed. Please check the implementation.")
    
    return failed == 0


if __name__ == "__main__":
    success = run_all_tests()
    exit(0 if success else 1) 